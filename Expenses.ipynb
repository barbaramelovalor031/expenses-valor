{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh7qu-cAKLke",
        "outputId": "313046e0-3618-4658-e9b3-f2d8bdd89e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.1.0\n",
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.28.1)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.12.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: invoke, eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.3.1 invoke-2.2.1 mistralai-1.9.11\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber pandas\n",
        "!pip install mistralai\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVB Card**"
      ],
      "metadata": {
        "id": "UhwZ_hpfoO6s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bVkP1mioMZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "pdf_path = \"SVB_Statement_2025-10-31 (1).pdf\"\n",
        "\n",
        "all_cardholders = {}\n",
        "lines = []\n",
        "\n",
        "# Extrai todas as linhas de texto do PDF\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            lines.extend(text.split(\"\\n\"))\n",
        "\n",
        "def clean_amount(raw_value):\n",
        "    \"\"\"\n",
        "    Normaliza o valor num√©rico:\n",
        "    - remove $ e v√≠rgulas\n",
        "    - converte par√™nteses e tra√ßos longos (‚Äì, ‚àí) em valores negativos\n",
        "    \"\"\"\n",
        "    value = raw_value.strip()\n",
        "    value = value.replace(\"$\", \"\").replace(\",\", \"\")\n",
        "    # Par√™nteses = negativo\n",
        "    if re.match(r\"^\\(.*\\)$\", value):\n",
        "        value = \"-\" + value.strip(\"()\")\n",
        "    # Tra√ßo longo ou similar\n",
        "    value = value.replace(\"‚Äì\", \"-\").replace(\"‚àí\", \"-\").strip()\n",
        "    try:\n",
        "        return float(value)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def parse_transaction_line(line):\n",
        "    \"\"\"\n",
        "    Detecta linhas de transa√ß√µes no formato: MM-DD-YY <descri√ß√£o> <valor>\n",
        "    Inclui negativos, com ou sem cifr√£o.\n",
        "    Ex: '10-31-25 UBER TRIP (12.34)'\n",
        "        '10-31-25 AMAZON  -$123.45'\n",
        "    \"\"\"\n",
        "    # Casa: data + descri√ß√£o + √∫ltimo \"token\" sendo o valor\n",
        "    match = re.match(\n",
        "        r\"(\\d{2}-\\d{2}-\\d{2})\\s+(.+?)\\s+(\\(?-?\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?\\)?)$\",\n",
        "        line.strip()\n",
        "    )\n",
        "    if match:\n",
        "        date_str = match.group(1)\n",
        "        desc = match.group(2).strip()\n",
        "        raw_amount = match.group(3)\n",
        "\n",
        "        # Data normalizada\n",
        "        try:\n",
        "            date_obj = datetime.strptime(date_str, \"%m-%d-%y\")\n",
        "            date_fmt = date_obj.strftime(\"%Y-%m-%d\")\n",
        "        except Exception:\n",
        "            date_fmt = date_str  # fallback se der erro\n",
        "\n",
        "        # Valor normalizado\n",
        "        amount = clean_amount(raw_amount)\n",
        "        if amount is None:\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            \"Date\": date_fmt,\n",
        "            \"Description\": desc,\n",
        "            \"Amount\": amount,\n",
        "            \"MCC\": \"\",\n",
        "            \"Merchant ZIP\": \"\",\n",
        "            \"Description / Notes\": \"\"\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Padr√£o para detectar o titular (nome + total da conta)\n",
        "cardholder_pattern = re.compile(r\"^(.*?) TOTAL FOR ACCOUNT ENDING IN \\d+.*$\", re.IGNORECASE)\n",
        "\n",
        "pending_tx = []\n",
        "pending_idx = []\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    holder_match = cardholder_pattern.match(line)\n",
        "    tx = parse_transaction_line(line)\n",
        "\n",
        "    # Se for uma transa√ß√£o, guarda temporariamente\n",
        "    if tx:\n",
        "        pending_tx.append(tx)\n",
        "        pending_idx.append(i)\n",
        "\n",
        "    # Se for linha de titular, associa as transa√ß√µes pendentes a esse titular\n",
        "    elif holder_match:\n",
        "        cardholder = holder_match.group(1).strip()\n",
        "        if pending_tx:\n",
        "            # Para cada transa√ß√£o, busca MCC e ZIP nas pr√≥ximas 2 linhas\n",
        "            for j, tx_item in enumerate(pending_tx):\n",
        "                idx = pending_idx[j]\n",
        "                next_lines = lines[idx + 1: idx + 3]\n",
        "                context = \" \".join(next_lines)\n",
        "                mcc_match = re.search(r\"MCC:\\s*(\\d+)\", context)\n",
        "                zip_match = re.search(r\"MERCHANT ZIP:\\s*(\\d+)\", context)\n",
        "                tx_item[\"MCC\"] = mcc_match.group(1) if mcc_match else \"\"\n",
        "                tx_item[\"Merchant ZIP\"] = zip_match.group(1) if zip_match else \"\"\n",
        "\n",
        "            # Armazena as transa√ß√µes do titular\n",
        "            all_cardholders.setdefault(cardholder, []).extend(pending_tx)\n",
        "\n",
        "            # Limpa pend√™ncias\n",
        "            pending_tx = []\n",
        "            pending_idx = []\n",
        "\n",
        "# üîπ Tratamento extra: se o PDF n√£o tiver se√ß√µes por cardholder,\n",
        "# mas tiver transa√ß√µes pendentes, jogamos tudo em uma aba gen√©rica\n",
        "if pending_tx:\n",
        "    # tenta descobrir o n√∫mero da conta pra ficar mais bonitinho\n",
        "    acct_match = None\n",
        "    for line in lines:\n",
        "        m = re.search(r\"Account Number:\\s+Ending in\\s+(\\d+)\", line)\n",
        "        if m:\n",
        "            acct_match = m\n",
        "            break\n",
        "\n",
        "    if acct_match:\n",
        "        holder_name = f\"Account {acct_match.group(1)}\"\n",
        "    else:\n",
        "        holder_name = \"All Transactions\"\n",
        "\n",
        "    all_cardholders.setdefault(holder_name, []).extend(pending_tx)\n",
        "    pending_tx = []\n",
        "    pending_idx = []\n",
        "\n",
        "# Exporta para Excel: uma aba por cardholder\n",
        "if not all_cardholders:\n",
        "    print(\"Nenhum cardholder/transa√ß√£o encontrado. Nada foi exportado.\")\n",
        "else:\n",
        "    output_path = \"extrato_svb_by_cardholder.xlsx\"\n",
        "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
        "        for cardholder, transactions in all_cardholders.items():\n",
        "            df = pd.DataFrame(transactions)\n",
        "\n",
        "            # Mantemos s√≥ as colunas principais (pode adicionar MCC/ZIP se quiser)\n",
        "            df = df[[\"Date\", \"Description\", \"Amount\"]]\n",
        "\n",
        "            # Ordena por data\n",
        "            df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "            # Excel limita o nome da sheet a 31 caracteres\n",
        "            sheet_name = cardholder[:31]\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Exportado para {output_path} com uma aba por cardholder (incluindo negativos)!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QhQxA-ZZUf8",
        "outputId": "3679133a-3998-4fc0-ffc6-167f55218434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exportado para extrato_svb_by_cardholder.xlsx com uma aba por cardholder (incluindo negativos)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amex Card**"
      ],
      "metadata": {
        "id": "kku3fXNpoZ50"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4iRTr8hToeeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "pdf_path = \"Amex 2025-11-07.pdf\"   # arquivo AMEX\n",
        "\n",
        "# ---------- Utils ----------\n",
        "def normalize(s: str) -> str:\n",
        "    return s.replace(\"‚Äì\", \"-\").replace(\"‚àí\", \"-\").replace(\"‚ß´\", \"\").strip()\n",
        "\n",
        "def clean_amount(token: str):\n",
        "    \"\"\"Normaliza $ e negativos: -$123.45, ($123.45)\"\"\"\n",
        "    t = normalize(token).replace(\"$\", \"\").replace(\",\", \"\").strip()\n",
        "    if re.fullmatch(r\"\\(\\s*\\d+(?:\\.\\d{2})?\\s*\\)\", t):\n",
        "        t = \"-\" + t.strip(\"()\").strip()\n",
        "    try:\n",
        "        return float(t)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# === padr√µes ===\n",
        "DATE_RE = re.compile(r\"^(\\d{2}/\\d{2}/\\d{2})\\s+(.*)$\")\n",
        "AMOUNT_TOKEN_RE = re.compile(\n",
        "    r\"(?:-?\\$\\s*\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)|(?:\\(\\s*\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?\\s*\\))\"\n",
        ")\n",
        "PAGE_FOOTER_RE = re.compile(r\"\\bp\\.\\s*\\d+/\\d+\\s*$\", re.IGNORECASE)\n",
        "\n",
        "# palavras que indicam in√≠cio e fim de se√ß√µes que devemos ignorar\n",
        "FEES_START = (\"FEES\",)\n",
        "INTEREST_START = (\"INTEREST CHARGED\",)\n",
        "SECTION_END = (\n",
        "    \"TOTAL FEES FOR THIS PERIOD\",\n",
        "    \"TOTAL INTEREST CHARGED FOR THIS PERIOD\",\n",
        "    \"ABOUT TRAILING INTEREST\",\n",
        "    \"IMPORTANT NOTICES\",\n",
        ")\n",
        "\n",
        "# tamb√©m ignorar linhas de cabe√ßalho / navega√ß√£o\n",
        "SKIP_PREFIXES = (\n",
        "    \"FOREIGN\", \"SPEND\", \"AMOUNT\", \"DETAIL\", \"CONTINUED ON NEXT PAGE\",\n",
        ")\n",
        "\n",
        "def is_page_footer(line: str) -> bool:\n",
        "    L = normalize(line)\n",
        "    return bool(PAGE_FOOTER_RE.search(L))\n",
        "\n",
        "def is_cardholder_header(lines, i):\n",
        "    \"\"\"\n",
        "    Detecta headers do cardholder em dois formatos:\n",
        "      A) <NAME IN UPPERCASE>, pr√≥xima(s) linha(s) cont√™m 'Card Ending'\n",
        "      B) Topo de p√°gina: linhas pr√≥ximas cont√™m 'Account Ending' ou 'Closing Date'\n",
        "    \"\"\"\n",
        "    line = normalize(lines[i])\n",
        "    if not line or line != line.upper():\n",
        "        return None\n",
        "    if not re.fullmatch(r\"[A-Z .'\\-]+\", line):\n",
        "        return None\n",
        "\n",
        "    lookahead = \" \".join(normalize(lines[i+k]) for k in range(1, 4) if i+k < len(lines))\n",
        "    if (\"CARD ENDING\" in lookahead.upper()) or (\"ACCOUNT ENDING\" in lookahead.upper()) or (\"CLOSING DATE\" in lookahead.upper()):\n",
        "        return line  # nome (ex.: 'KELLI SPANGLER' / 'SCOTT SOBEL')\n",
        "    return None\n",
        "\n",
        "def extract_amount_and_clean(desc_block: str):\n",
        "    \"\"\"\n",
        "    Pega o √öLTIMO token monet√°rio no bloco (s√≥ $ ou par√™nteses),\n",
        "    remove-o do texto e retorna (amount_float, descricao_limpa).\n",
        "    \"\"\"\n",
        "    block = normalize(desc_block)\n",
        "    matches = list(AMOUNT_TOKEN_RE.finditer(block))\n",
        "    amount = None\n",
        "    if matches:\n",
        "        m = matches[-1]\n",
        "        amt_raw = block[m.start():m.end()]\n",
        "        amount = clean_amount(amt_raw)\n",
        "        block = (block[:m.start()] + block[m.end():]).strip()\n",
        "        block = re.sub(r\"\\s{2,}\", \" \", block).strip(\" -|,\")\n",
        "    return amount, block\n",
        "\n",
        "def parse_amex(pdf_path):\n",
        "    lines = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            t = page.extract_text()\n",
        "            if t:\n",
        "                lines.extend(t.split(\"\\n\"))\n",
        "\n",
        "    all_cardholders = {}\n",
        "    current_holder = None\n",
        "\n",
        "    # estado de se√ß√£o a ignorar\n",
        "    skip_mode = None  # None | 'fees' | 'interest'\n",
        "\n",
        "    i, N = 0, len(lines)\n",
        "    while i < N:\n",
        "        raw = lines[i]\n",
        "        line = normalize(raw)\n",
        "        upper = line.upper()\n",
        "\n",
        "        # --- detectar mudan√ßa de cardholder (fecha skip_mode tamb√©m) ---\n",
        "        holder = is_cardholder_header(lines, i)\n",
        "        if holder:\n",
        "            current_holder = holder.title()\n",
        "            all_cardholders.setdefault(current_holder, [])\n",
        "            skip_mode = None\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # --- entrar/sair de se√ß√µes Fees/Interest ---\n",
        "        if skip_mode is None and upper.startswith(FEES_START):\n",
        "            skip_mode = 'fees'\n",
        "            i += 1\n",
        "            continue\n",
        "        if skip_mode is None and upper.startswith(INTEREST_START):\n",
        "            skip_mode = 'interest'\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        if skip_mode is not None:\n",
        "            # enquanto em fees/interest, ignorar tudo at√© marcador de t√©rmino,\n",
        "            # novo cardholder, topo de p√°gina ou fim\n",
        "            if is_cardholder_header(lines, i) or is_page_footer(line) or any(upper.startswith(x) for x in SECTION_END):\n",
        "                skip_mode = None\n",
        "                # n√£o avan√ßamos aqui; deixa a itera√ß√£o reprocessar esta linha (pode ser header)\n",
        "            else:\n",
        "                i += 1\n",
        "            continue\n",
        "\n",
        "        # ignorar cabe√ßalhos avulsos\n",
        "        if upper.startswith(SKIP_PREFIXES) or is_page_footer(line):\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # --- transa√ß√£o: come√ßa com MM/DD/YY ---\n",
        "        m = DATE_RE.match(line)\n",
        "        if m and current_holder:\n",
        "            date_s, first_desc = m.group(1), m.group(2).strip()\n",
        "            try:\n",
        "                date_fmt = datetime.strptime(date_s, \"%m/%d/%y\").strftime(\"%Y-%m-%d\")\n",
        "            except Exception:\n",
        "                date_fmt = date_s\n",
        "\n",
        "            # acumula linhas do bloco at√© pr√≥xima data, novo holder, ou in√≠cio de se√ß√£o\n",
        "            block_lines = [first_desc] if first_desc else []\n",
        "            j = i + 1\n",
        "            while j < N:\n",
        "                nxt = normalize(lines[j])\n",
        "                up = nxt.upper()\n",
        "\n",
        "                if is_cardholder_header(lines, j):\n",
        "                    break\n",
        "                if DATE_RE.match(nxt):\n",
        "                    break\n",
        "                if up.startswith(FEES_START) or up.startswith(INTEREST_START):\n",
        "                    break\n",
        "                if any(up.startswith(x) for x in SECTION_END):\n",
        "                    break\n",
        "                if up.startswith(SKIP_PREFIXES) or is_page_footer(nxt):\n",
        "                    j += 1\n",
        "                    continue\n",
        "\n",
        "                block_lines.append(nxt)\n",
        "                j += 1\n",
        "\n",
        "            block_text = \" \".join([b for b in block_lines if b]).strip()\n",
        "            amount, description = extract_amount_and_clean(block_text)\n",
        "\n",
        "            all_cardholders[current_holder].append({\n",
        "                \"Date\": date_fmt,\n",
        "                \"Description\": description,\n",
        "                \"Amount\": amount,\n",
        "            })\n",
        "\n",
        "            i = j\n",
        "            continue\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return all_cardholders\n",
        "\n",
        "# ---------- Rodar e exportar ----------\n",
        "data = parse_amex(pdf_path)\n",
        "# ---------- Exportar com toler√¢ncia a vazios ----------\n",
        "out_path = \"amex_by_cardholder.xlsx\"\n",
        "\n",
        "written_any = False\n",
        "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
        "    for holder, txs in data.items():\n",
        "        # Constr√≥i DF e garante as colunas mesmo se vazio\n",
        "        df = pd.DataFrame(txs if txs else [])\n",
        "        for col in [\"Date\", \"Description\", \"Amount\"]:\n",
        "            if col not in df.columns:\n",
        "                df[col] = pd.Series(dtype=\"object\")\n",
        "\n",
        "        # Ordena e reindexa colunas no padr√£o\n",
        "        df = df[[\"Date\", \"Description\", \"Amount\"]]\n",
        "        df[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\n",
        "\n",
        "        # Se n√£o tiver nenhuma linha, pula a aba (n√£o cria planilha vazia)\n",
        "        if df.empty:\n",
        "            print(f\"[Info] {holder}: 0 transa√ß√µes (aba n√£o criada).\")\n",
        "            continue\n",
        "\n",
        "        sheet = (holder or \"Unassigned\")[:31]\n",
        "        df.sort_values([\"Date\", \"Description\"], na_position=\"last\").to_excel(\n",
        "            writer, index=False, sheet_name=sheet\n",
        "        )\n",
        "        written_any = True\n",
        "        print(f\"[OK] {holder}: {len(df)} transa√ß√µes.\")\n",
        "\n",
        "    # Garante pelo menos UMA planilha vis√≠vel\n",
        "    if not written_any:\n",
        "        pd.DataFrame(columns=[\"Date\", \"Description\", \"Amount\"]).to_excel(\n",
        "            writer, index=False, sheet_name=\"Summary\"\n",
        "        )\n",
        "        print(\"[Warn] Nenhuma transa√ß√£o v√°lida encontrada. Criada aba 'Summary' vazia.\")\n",
        "\n",
        "print(f\"‚úÖ Exportado: {out_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg4u-ZMRhKIY",
        "outputId": "84a05c7e-4bd9-4cd5-d23d-c2c4460c6a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Valor Capital Group: 0 transa√ß√µes (aba n√£o criada).\n",
            "[OK] Scott Sobel: 2 transa√ß√µes.\n",
            "[Info] Telecommunications: 0 transa√ß√µes (aba n√£o criada).\n",
            "[OK] John Douglas Smith: 9 transa√ß√µes.\n",
            "[OK] Kelli Spangler: 7 transa√ß√µes.\n",
            "‚úÖ Exportado: amex_by_cardholder.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bradesco**"
      ],
      "metadata": {
        "id": "PXekjB4bpxiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import math\n",
        "\n",
        "pdf_path = \"Bradesco_03122025_104350.PDF\"\n",
        "out_path = \"bradesco_card_statement_with_fx.xlsx\"\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def normalize(s: str) -> str:\n",
        "    return s.replace(\"\\u00a0\", \" \").strip() if s else \"\"\n",
        "\n",
        "def parse_brl_number(tok: str):\n",
        "    \"\"\"\n",
        "    Converte:\n",
        "      '1.234,56'  -> 1234.56\n",
        "      '0,00'      -> 0.0\n",
        "      '(123,45)'  -> -123.45\n",
        "      '-1.234,56' -> -1234.56\n",
        "    \"\"\"\n",
        "    if tok is None:\n",
        "        return None\n",
        "    t = normalize(tok)\n",
        "    negative = False\n",
        "    if t.startswith(\"(\") and t.endswith(\")\"):\n",
        "        negative = True\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"R$\", \"\").replace(\"$\", \"\").replace(\" \", \"\")\n",
        "    # primeiro tira separador de milhar\n",
        "    t = t.replace(\".\", \"\")\n",
        "    # depois converte v√≠rgula em ponto\n",
        "    t = t.replace(\",\", \".\")\n",
        "    if t.startswith(\"-\"):\n",
        "        negative = True\n",
        "        t = t[1:]\n",
        "    try:\n",
        "        val = float(t)\n",
        "        return -val if negative else val\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# ---------- L√™ PDF e coleta linhas ----------\n",
        "lines = []\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        txt = page.extract_text()\n",
        "        if txt:\n",
        "            lines.extend([normalize(l) for l in txt.split(\"\\n\")])\n",
        "\n",
        "# ---------- Descobre ano e nome do titular ----------\n",
        "year = None\n",
        "holder = \"Cardholder\"\n",
        "\n",
        "for l in lines:\n",
        "    # ex: \"M√™s: Setembro/2025\"\n",
        "    m_month = re.search(r\"M[e√™]s:\\s*\\w+\\/(\\d{4})\", l, flags=re.IGNORECASE)\n",
        "    if m_month:\n",
        "        year = int(m_month.group(1))\n",
        "\n",
        "    m_name = re.search(r\"^Nome:\\s*(.+)$\", l, flags=re.IGNORECASE)\n",
        "    if m_name:\n",
        "        holder = m_name.group(1).strip()\n",
        "\n",
        "if year is None:\n",
        "    m_any = re.search(r\"(20\\d{2})\", \" \".join(lines))\n",
        "    year = int(m_any.group(1)) if m_any else datetime.now().year\n",
        "\n",
        "# ---------- Parse das transa√ß√µes ----------\n",
        "# padr√£o de dinheiro BR (ex.: 0,00 | 1.399,76 | (123,45))\n",
        "MONEY_BR = r\"\\(?-?\\d{1,3}(?:\\.\\d{3})*,\\d{2}\\)?\"\n",
        "\n",
        "# dd/mm  DESCRI√á√ÉO  US$  R$\n",
        "row_re = re.compile(\n",
        "    rf\"^(\\d{{2}}/\\d{{2}})\\s+(.+?)\\s+({MONEY_BR})\\s+({MONEY_BR})\\s*$\"\n",
        ")\n",
        "\n",
        "txs = []\n",
        "for l in lines:\n",
        "    if l.upper().startswith((\"DATA HIST√ìRICO\", \"DATA HISTORICO\")):\n",
        "        continue\n",
        "    if l.upper().startswith(\"TOTAL:\"):\n",
        "        continue\n",
        "\n",
        "    m = row_re.match(l)\n",
        "    if not m:\n",
        "        # Fallback: pega os DOIS √∫ltimos tokens monet√°rios da linha\n",
        "        money_matches = list(re.finditer(MONEY_BR, l))\n",
        "        if len(money_matches) < 2:\n",
        "            continue\n",
        "        m_usd, m_brl = money_matches[-2], money_matches[-1]\n",
        "\n",
        "        # data dd/mm no come√ßo\n",
        "        m_date = re.match(r\"^(\\d{2}/\\d{2})\\s+\", l)\n",
        "        if not m_date:\n",
        "            continue\n",
        "        ddmm = m_date.group(1)\n",
        "\n",
        "        # descri√ß√£o = entre a data e o primeiro valor monet√°rio\n",
        "        desc = l[m_date.end(): m_usd.start()].strip()\n",
        "        usd_raw = l[m_usd.start(): m_usd.end()]\n",
        "        brl_raw = l[m_brl.start(): m_brl.end()]\n",
        "    else:\n",
        "        ddmm, desc, usd_raw, brl_raw = m.groups()\n",
        "\n",
        "    day, month = ddmm.split(\"/\")\n",
        "    try:\n",
        "        date_fmt = datetime(year=int(year), month=int(month), day=int(day)).strftime(\"%Y-%m-%d\")\n",
        "    except ValueError:\n",
        "        date_fmt = f\"{day}/{month}/{year}\"\n",
        "\n",
        "    amount_usd = parse_brl_number(usd_raw)\n",
        "    amount_brl = parse_brl_number(brl_raw)\n",
        "\n",
        "    txs.append({\n",
        "        \"Date\": date_fmt,\n",
        "        \"Description\": desc.strip(),\n",
        "        \"Amount_USD\": amount_usd,\n",
        "        \"Amount_BRL\": amount_brl,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(txs)\n",
        "\n",
        "# Garante colunas mesmo se vazio\n",
        "for col in [\"Date\", \"Description\", \"Amount_USD\", \"Amount_BRL\"]:\n",
        "    if col not in df.columns:\n",
        "        df[col] = pd.Series(dtype=\"object\")\n",
        "\n",
        "# ---------- Fun√ß√£o para buscar PTAX por data ----------\n",
        "def get_cotacao_dolar_ptax(data_iso: str, cache: dict):\n",
        "    \"\"\"\n",
        "    data_iso no formato YYYY-MM-DD.\n",
        "    Usa a API PTAX do Bacen, com fallback para dia √∫til anterior.\n",
        "    Retorna a cotacaoVenda (fechamento) como float.\n",
        "    \"\"\"\n",
        "    if data_iso in cache:\n",
        "        return cache[data_iso]\n",
        "\n",
        "    # tenta at√© 7 dias pra tr√°s (fim de semana/feriado)\n",
        "    dt = datetime.strptime(data_iso, \"%Y-%m-%d\")\n",
        "    for _ in range(7):\n",
        "        data_bcb = dt.strftime(\"%m-%d-%Y\")  # MM-DD-YYYY\n",
        "        url = (\n",
        "            \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/\"\n",
        "            f\"CotacaoDolarDia(dataCotacao=@dataCotacao)?\"\n",
        "            f\"@dataCotacao='{data_bcb}'&$top=100&$format=json\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            resp = requests.get(url, timeout=10)\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Erro ao buscar PTAX para {data_iso} ({data_bcb}): {e}\")\n",
        "            cache[data_iso] = None\n",
        "            return None\n",
        "\n",
        "        valores = data.get(\"value\", [])\n",
        "        if valores:\n",
        "            ultimo = valores[-1]\n",
        "            rate = float(ultimo[\"cotacaoVenda\"])\n",
        "            cache[data_iso] = rate\n",
        "            return rate\n",
        "\n",
        "        # se n√£o achou, vai um dia pra tr√°s\n",
        "        dt = dt - timedelta(days=1)\n",
        "\n",
        "    # se n√£o encontrou nada em 7 dias, cacheia como None\n",
        "    cache[data_iso] = None\n",
        "    return None\n",
        "\n",
        "# ---------- Aplica c√¢mbio e converte BRL -> USD ----------\n",
        "if not df.empty:\n",
        "    fx_cache = {}\n",
        "\n",
        "    def fx_for_row(date_str):\n",
        "        if not isinstance(date_str, str):\n",
        "            return None\n",
        "        return get_cotacao_dolar_ptax(date_str, fx_cache)\n",
        "\n",
        "    df[\"FX_BRLUSD\"] = df[\"Date\"].apply(fx_for_row)\n",
        "\n",
        "    def convert_brl_to_usd(row):\n",
        "        brl = row[\"Amount_BRL\"]\n",
        "        fx = row[\"FX_BRLUSD\"]\n",
        "        if brl is None or pd.isna(brl) or fx is None or pd.isna(fx) or fx == 0:\n",
        "            return None\n",
        "        return brl / fx\n",
        "\n",
        "    df[\"Final Amount\"] = df.apply(convert_brl_to_usd, axis=1).round(2)\n",
        "    df = df[['Date','Description','Amount_BRL','FX_BRLUSD','Final Amount']]\n",
        "\n",
        "    # Ordena por data e descri√ß√£o\n",
        "    df = df.sort_values([\"Date\", \"Description\"], na_position=\"last\")\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Exporta para Excel ----------\n",
        "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
        "    sheet = holder[:31] if holder else \"Bradesco\"\n",
        "    df.to_excel(writer, index=False, sheet_name=sheet)\n",
        "\n",
        "print(f\"‚úÖ Exportado: {out_path} (aba: {sheet}, {len(df)} linhas)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzXPedNovorh",
        "outputId": "e2602f16-e3c5-4b73-d6ae-3cafffb405d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exportado: bradesco_card_statement_with_fx.xlsx (aba: FELIPE M SANTOS - AMEX, 12 linhas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b-8wcnyrp6FU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}